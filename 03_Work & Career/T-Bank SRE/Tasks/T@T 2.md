Хорошая идея: начинать с самых мощных задач, где у тебя и импакт, и сложность, и ответственность.  
Предлагаю порядок такой (по убыванию «крутости»):

1. Надёжность LCC-routing (алерт + валидация + автомерж).
    
2. Автоматика по квотам/топикам в Luna (логопровод).
    
3. Эксперимент с увеличением объёма данных в Elastic.
    
4. Инфраструктура: ansible / sage-horde / OSProxy / sageDB.
    
5. Kibana UI для траблшутинга Elastic.
    
6. Документация / релиз-менеджмент (Release Notes 1.11).
    

Ниже — полностью готовые блоки задач в нужном формате, уже **упорядоченные от самых «жирных» к более вспомогательным**. Можешь копировать в заявку и подправить под свои детали (имена людей и ссылки).

---

### Задача 1

**Повышение надёжности LCC-routing через алерты и строгую валидацию конфигов**  
_SAGE-23670, SAGE-22572, SAGE-23322_

#### Описание задачи

LCC-routing отвечает за то, чтобы логи групп доходили до нужных мест. Любые ошибки в конфигурации роутинга или «пропавшие» роуты приводят к тому, что:

- часть логов теряется по дороге,
    
- инциденты замечаются только по жалобам или уже по красным алертам.
    

Основные проблемы были такие:

- всплески «пропавших роутов» выявлялись поздно;
    
- автомерж в `lcc-furry-routing` могли делать люди, что повышало риск некорректных конфигов в проде;
    
- валидация конфигов LCC происходила слишком поздно, ошибки ловились уже близко к продакшену.
    

В рамках набора задач я:

- добавил алерт на большое количество пропавших роутов;
    
- включил автомерж в `lcc-furry-routing` только для сервисного робота;
    
- перенёс валидацию конфигов LCC на этап MR в репозитории `lcc-furry-settings`.
    

#### Итоги работы

- Появился алерт, который отслеживает аномальное количество пропавших роутов — команда теперь видит проблему раньше, чем это превращается в полноценный инцидент.
    
- Автомерж в `lcc-furry-routing` теперь происходит строго через робота и только после прохождения проверок, что уменьшает риск «случайных» мержей человеком.
    
- Валидация конфигов LCC перенесена на стадию MR: некорректные конфиги отсеиваются ещё до деплоя, а не в продакшене.
    
- В целом снизился риск того, что из-за человеческого фактора или неправильного конфига часть логов потеряется или будет маршрутизирована не туда.
    

Закрывает скоупы:

- **Execution** — практически полезные изменения, влияющие на стабильность прод-системы.
    
- **Knowledge** — понимание устройства LCC, пайплайна конфигов и алертинга.
    

#### Кто участвовал в реализации задачи

Я был инженером:

- проанализировал, где и почему теряются роуты,
    
- спроектировал и реализовал алерт на пропавшие роуты,
    
- настроил ограничения на автомерж в `lcc-furry-routing`,
    
- перенёс валидацию конфигов LCC в пайплайн MR и проверил, что она работает корректно на реальных изменениях.
    

Тимлид и коллеги по LCC консультировали по бизнес-требованиям к алертам и помогали ревьюить MR.

#### Теги матрицы уровней

Execution, Knowledge

#### Ссылки

- SAGE-23670 — Алерт на большое количество пропавших роутов
    
- SAGE-22572 — Включить автомерж в lcc-furry-routing только для робота
    
- SAGE-23322 — [lcc-furry-settings] Перенести валидацию конфигов lcc на этап MR
    
- MR с добавлением алерта и порогов — <ссылка>
    
- MR с настройками автомержа — <ссылка>
    
- MR с валидацией конфигов lcc в пайплайне — <ссылка>
    

---

### Задача 2

**Автоматизация управления квотами и топиками логов в Luna**  
_SAGE-19623, SAGE-25089 (+ техдолг: SAGE-26703, SAGE-22150)_

#### Описание задачи

В Sage квоты на логи и Kafka-топики под них управляются через Luna. Исторически часть логики жила в ручных процессах или «костылях», из-за этого:

- квоты могли оставаться завышенными или некорректными;
    
- создавались лишние Kafka-топики для групп, у которых фактически не настроен `KafkaForLogs`;
    
- в Луне висел устаревший функционал (Elastic Admin Template, OmgScan), который усложнял код и путал новых инженеров.
    

В рамках задач я:

- добавил в Luna джобу по автоматическому «обрезанию» квоты до нужного состояния;
    
- изменил логику так, чтобы топики не создавались, если не настроен `KafkaForLogs`;
    
- выпилил из Luna legacy-функциональность (`Elastic Admin Template`, `OmgScan`), которая больше не использовалась.
    

#### Итоги работы

- Появилась автоматическая джоба в Luna, которая регулярно приводит квоты к ожидаемому значению без ручного вмешательства инженера.
    
- Создание логовых топиков стало безопаснее: теперь не создаются «мусорные» топики для групп без `KafkaForLogs`.
    
- Код Luna стал проще: удалена неиспользуемая функциональность, уменьшилось количество путаницы для новых инженеров.
    
- В результате уменьшился риск неконтролируемого роста нагрузки на Kafka/Elastic и сократился объём ручной рутины у дежурных.
    

Закрывает скоупы:

- **Execution** — законченный полезный функционал в проде.
    
- **Knowledge** — понимание взаимодействия квот, Kafka и Elastic через Luna, работа с техдолгом.
    

#### Кто участвовал в реализации задачи

Я был инженером:

- разобрался в существующей логике работы квот и топиков,
    
- спроектировал поведение джобы по коррекции квот и защиту от создания топиков без `KafkaForLogs`,
    
- реализовал и протестировал изменения в Luna,
    
- аккуратно выпилил legacy-функционал, убедившись, что он не используется, и задокументировал изменения.
    

Тимлид/старший инженер помогали с ревью и проверкой, что изменения не ломают существующие сценарии.

#### Теги матрицы уровней

Execution, Knowledge

#### Ссылки

- SAGE-19623 — [Luna] Джоба по обрезанию квоты
    
- SAGE-25089 — [Luna] Не создавать топик, если не указана KafkaForLogs
    
- SAGE-26703 — Выпилить Elastic Admin Template в Луне
    
- SAGE-22150 — Удалить OmgScan из Луны
    
- MR с реализацией джобы и логики по KafkaForLogs — <ссылка>
    
- MR с выпиливанием legacy-кода — <ссылка>
    

---

### Задача 3

**Эксперимент по увеличению объёма хранимых данных в Elastic**  
_SAGE-25621_

#### Описание задачи

Команде нужно было понять, как безопасно увеличивать срок хранения логов и объём данных в Elastic. Проблемы:

- мы не до конца понимали, как изменение retention влияет на занятое дисковое пространство и нагрузку на кластера;
    
- решения принимались довольно консервативно, чтобы не уронить кластера по диску, но при этом хотелось хранить логи дольше.
    

Задача — провести контролируемый эксперимент на выбранных кластерах Elastic:

- изменить настройки хранения,
    
- посмотреть на метрики в динамике,
    
- сформулировать рекомендации, где и как можно безопасно увеличивать объём хранимых данных.
    

#### Итоги работы

- Подготовил экспериментальную конфигурацию Elastic под увеличенный объём/retention на выбранных кластерах и согласовал её с командой.
    
- Настроил наблюдение за ключевыми метриками (занятое место, нагрузка) и провёл эксперимент.
    
- Описал результаты и выводы в Confluence: в каких сценариях и с какими ограничениями можно поднимать срок хранения логов, где запас по диску достаточен, а где нужен более аккуратный подход.
    
- Полученные рекомендации используются как база для дальнейших решений по ретеншену и балансировке данных между кластерами.
    

Закрывает скоупы:

- **Execution** — завершённая практическая задача, влияющая на планирование ресурсов.
    
- **Knowledge** — понимание поведения Elastic под ростом данных и работа с наблюдаемостью/метриками.
    

#### Кто участвовал в реализации задачи

Я был инженером:

- выбрал кластера/группы для эксперимента,
    
- подготовил и применил конфигурацию,
    
- наблюдал за метриками, собрал результаты и оформил выводы.
    

Старший инженер/тимлид помогали с выбором кластеров и согласованием финальных рекомендаций.

#### Теги матрицы уровней

Execution, Knowledge

#### Ссылки

- SAGE-25621 — [Эксперимент] Настройка по увеличению объёма хранимых данных на Elastic
    
- Страница с описанием эксперимента и выводами в Confluence — <ссылка>
    
- Использованные дашборды/метрики — <ссылка>
    

---

### Задача 4

**Инфраструктура: запуск ansible-плейбуков и перевод sageDB на новый OSProxy**  
_SAGE-26599, SAGE-26600, SAGE-25909_

#### Описание задачи

Для управления инфраструктурой Sage используются ansible-плейбуки и `sage-horde`. Ранее запуск части плейбуков был менее стандартизирован и требовал:

- знания внутренних деталей,
    
- лишних ручных шагов,
    
- времени старших инженеров на сопровождение.
    

Параллельно шёл проект по переводу `sageDB` на новый OSProxy, чтобы:

- унифицировать доступ к базе,
    
- упростить сопровождение,
    
- подготовиться к вывозу старого прокси.
    

Моя задача:

- настроить удобный и стандартный запуск плейбуков из общих репозиториев ansible и `sage-horde`;
    
- помочь перевести `sageDB` на новый OSProxy, не поломав продуктивную нагрузку.
    

#### Итоги работы

- Настроен запуск ключевых ansible-плейбуков из нужных репозиториев в понятном и фиксированном виде, что снижает порог входа для новых SRE и уменьшает шанс ошибок при запуске.
    
- `sageDB` переведена на новый OSProxy, проверена работоспособность и наблюдаемость после перевода.
    
- Сценарии запуска плейбуков и перевода описаны в документации, их можно использовать в онбординге и дежурствах как понятный рецепт.
    

Закрывает скоупы:

- **Execution** — улучшение инфраструктуры, которое экономит время и уменьшает количество ручных операций.
    
- **Knowledge** — понимание ansible, `sage-horde`, OSProxy и схемы доступа к базам в Sage.
    

#### Кто участвовал в реализации задачи

Я был инженером:

- настроил запуск плейбуков из репозитория ansible и `sage-horde`, протестировал их на тестовых сценариях,
    
- участвовал в переводе `sageDB` на новый OSProxy, проверял конфигурацию и метрики после перевода,
    
- оформил инструкции в документации.
    

Коллеги по команде и владельцы `sageDB` принимали результат и давали фидбек по удобству сценариев.

#### Теги матрицы уровней

Execution, Knowledge

#### Ссылки

- SAGE-26599 — Настроить запуск плейбуков из репозитория ansible
    
- SAGE-26600 — Настроить запуск плейбуков из sage-horde
    
- SAGE-25909 — Переключить sageDB на новый OSProxy
    
- MR’ы с настройками запуска плейбуков — <ссылки>
    
- Документация по переводу `sageDB` — <ссылка>
    

---

### Задача 5

**Ускорение траблшутинга ElasticSearch через улучшение Kibana UI в Luna**  
_SAGE-23371, SAGE-27340_

#### Описание задачи

SRE и разработчики активно используют Kibana UI из Luna, чтобы:

- разбирать инциденты с ElasticSearch,
    
- смотреть индексы, запросы, ошибки и т.д.
    

Со временем интерфейс оброс кнопками и ссылками, и:

- стало трудно быстро находить нужное действие,
    
- стандартные сценарии диагностики занимали лишние шаги.
    

В рамках задач я:

- добавил больше «быстрых кнопок» в Kibana UI под популярные сценарии траблшутинга ES;
    
- структурировал и переупорядочил кнопки, чтобы интерфейс был логичнее и проще.
    

#### Итоги работы

- Основные сценарии траблшутинга Elastic (перейти к нужному индексу, посмотреть нужный дашборд, быстро попасть к логам проблемной группы и т.д.) стали занимать меньше кликов.
    
- Кнопки и действия в Kibana UI сгруппированы, интерфейс стал понятнее, особенно для новичков и дежурных, которые работают под давлением времени.
    
- Часть шагов в runbook’ах по Elastic теперь закрывается одним кликом через UI, а не ручными переходами.
    

Закрывает скоупы:

- **Execution** — полезные доработки интерфейса, ускоряющие работу команды.
    
- **Knowledge** — понимание типичных сценариев SRE и внутреннего устройства Kibana UI в Luna.
    

#### Кто участвовал в реализации задачи

Я был инженером:

- собрал потребности от команды по сценарию «как вы реально отлаживаете Elastic»,
    
- спроектировал новую структуру кнопок и быстрых действий,
    
- реализовал изменения и протестировал их вместе с коллегами,
    
- оформил описание нового UI в документации/вики.
    

Коллеги по Sage давали фидбек и помогали отшлифовать набор кнопок под реальные кейсы.

#### Теги матрицы уровней

Execution, Knowledge

#### Ссылки

- SAGE-23371 — [Luna] Добавить больше быстрых кнопок в Kibana UI для траблшутинга ES
    
- SAGE-27340 — [Luna] Структуризировать кнопки в Kibana UI
    
- MR с изменениями UI — <ссылка>
    
- Страница в Confluence с описанием нового UI — <ссылка>
    

---

### Задача 6

**Документация и релиз-менеджмент: Release Notes для Luna 1.11**  
_SAGE-28056_

#### Описание задачи

При релизе Luna 1.11 нужно было:

- собрать изменения из Jira и MR’ов,
    
- оформить их понятным языком для SRE и разработчиков,
    
- чтобы было ясно, что именно поменялось и на что смотреть, если после релиза появляются инциденты.
    

Цель — подготовить нормальные release notes, которые будут удобны и команде, и дежурным.

#### Итоги работы

- Собрал состав релиза 1.11 (задачи и MR’ы), сгруппировал изменения по типам: новые фичи, фиксы, инфраструктурные изменения.
    
- Описал, какие изменения потенциально рискованные и на что стоит обратить внимание при разборе инцидентов после релиза.
    
- Оформил release notes в одном месте (Confluence/репозиторий), чтобы команда и дежурные могли быстро понять контекст релиза.
    
- Снизилось количество вопросов «что именно выкатили?» и стало проще искать связи между релизом и эффектами в проде.
    

Закрывает скоупы:

- **Execution** — релиз сопровождается понятной документацией, помогающей всей команде.
    
- **Knowledge** — погружение в задачи релиза и их влияние на систему.
    

#### Кто участвовал в реализации задачи

Я был инженером:

- собрал список задач и MR’ов, вошедших в релиз 1.11,
    
- подготовил текст release notes,
    
- согласовал его с тимлидом и опубликовал в принятом месте.
    

Тимлид/ответственный за релиз помогали с проверкой формулировок и приоритизацией.

#### Теги матрицы уровней

Execution, Knowledge

#### Ссылки

- SAGE-28056 — [Luna] Написать Release Notes для 1.11
    
- Release Notes Luna 1.11 — <ссылка>
    

---

### Дополнительная активность (онбординг и учения)

Это можно оформить отдельным коротким блоком «Дополнительная активность»:

> **Онбординг и тренировочные активности SRE**
> 
> За время стажировки я прошёл полный онбординг в Sage:
> 
> - SAGE-26595 — SRE Onboarding: Радмир Исламов
>     
> - SAGE-26598 — Получить доступы, необходимые для Sage SRE
>     
> - SAGE-26612 — Учения по переносу группы средствами LCC
>     
> - SAGE-26604 — Учения по Sage k8s
>     
> - SAGE-26607 — Учения по рестарту различных сервисов и инфраструктуры Sage
>     
> - SAGE-26602 — Пройти курс «Пользовательский гайд по Sage»
>     
> - SAGE-26601 — Изучение MageQL + практика
>     
> 
> Эти задачи позволили мне:
> 
> - разобраться в основных компонентах платформы (LCC, k8s, Mage, Luna, инфраструктура Sage),
>     
> - научиться уверенно выполнять базовые операции (перенос групп, рестарт сервисов, работа с дашбордами и логами),
>     
> - участвовать в дежурствах без постоянной опеки старших ребят.
>     

---

Если хочешь, дальше можем:

- под каждую задачу прямо расписать теги из **SRE — Checklists** (конкретные пункты),
    
- или подсобрать из этого «сухой» вариант на тык-тык без лишних слов, чтобы было вообще «как у примера Олега».